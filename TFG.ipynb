{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Ubnei59PSUZ"
      },
      "source": [
        "# **Importación de las librerías**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-mMoW1i-wGBu"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score,\n",
        "    average_precision_score,\n",
        "    confusion_matrix,\n",
        "    ConfusionMatrixDisplay,\n",
        "    f1_score,\n",
        "    make_scorer,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        "    auc\n",
        ")\n",
        "from sklearn.model_selection import (\n",
        "    cross_validate,\n",
        "    RandomizedSearchCV,\n",
        "    StratifiedKFold,\n",
        ")\n",
        "from sklearn.inspection import permutation_importance\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.svm import SVC\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from scipy.stats import randint, uniform\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "import json\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3yKar4xY9q9"
      },
      "source": [
        "# Funciones auxiliares para la representación de los resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "avk05J_25OL8"
      },
      "source": [
        "## **Función para mostrar una matriz de confusión**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xiyLwEzm0SV5"
      },
      "outputs": [],
      "source": [
        "def mostrar_matriz_confusion(y_true, y_pred, modelo, title=None):\n",
        "    \"\"\"\n",
        "    Muestra la matriz de confusión para un conjunto de etiquetas reales y predichas.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): Etiquetas reales (verdaderas) del conjunto de datos.\n",
        "        y_pred (array-like): Etiquetas predichas por el modelo.\n",
        "        modelo (str): Nombre del modelo.\n",
        "        title (str, optional): Título personalizado para el gráfico. Si no se proporciona,\n",
        "                               se generará uno automáticamente con el nombre del modelo.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Saludable\", \"Quiebra\"])\n",
        "    disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "    plt.title(title if title else f\"Matriz de Confusión - {modelo.upper()}\")\n",
        "    plt.grid(False)\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Función para representar la curva ROC**"
      ],
      "metadata": {
        "id": "tlTsL7OF0EhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def graficar_curvas_roc_comparativas(validaciones_dict, title=\"Curvas ROC comparativas por modelo\"):\n",
        "    \"\"\"\n",
        "    Genera una gráfica comparativa de curvas ROC para los modelos dados.\n",
        "\n",
        "    Args:\n",
        "        validaciones_dict (dict): Diccionario con los resultados de test de cada modelo.\n",
        "                                  Cada valor debe tener un DataFrame con columnas 'Real' y 'Probabilidad_Quiebra'.\n",
        "        title (str, optional): Título del gráfico. Por defecto es 'Curvas ROC comparativas por modelo'.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    for modelo, datos in validaciones_dict.items():\n",
        "        y_true = datos[\"resultados\"][\"Real\"].values\n",
        "        y_scores = datos[\"resultados\"][\"Probabilidad_Quiebra\"].values\n",
        "        fpr, tpr, _ = roc_curve(y_true, y_scores)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'{modelo.upper()} (AUC = {roc_auc:.2f})')\n",
        "\n",
        "    plt.plot([0, 1], [0, 1], 'k--', lw=1)\n",
        "    plt.xlim([0.0, 1.0])\n",
        "    plt.ylim([0.0, 1.05])\n",
        "    plt.xlabel('Tasa de Falsos Positivos')\n",
        "    plt.ylabel('Tasa de Verdaderos Positivos')\n",
        "    plt.title(title)\n",
        "    plt.legend(loc=\"lower right\")\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "p47FXGEm0J-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3C7fMZ9M5tF0"
      },
      "source": [
        "## **Función para calcular las métricas de validación**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoAzfNgd5evO"
      },
      "outputs": [],
      "source": [
        "def calcular_metricas_validacion(y_true, y_pred, y_prob):\n",
        "    \"\"\"\n",
        "    Calcula un conjunto de métricas de evaluación para un modelo de clasificación binaria.\n",
        "\n",
        "    Calcula accuracy, F1-score, precisión, recall, especificidad y AUC-ROC a partir de\n",
        "    las etiquetas verdaderas, las predicciones y las probabilidades predichas.\n",
        "\n",
        "    Args:\n",
        "        y_true (array-like): Etiquetas verdaderas del conjunto de datos.\n",
        "        y_pred (array-like): Etiquetas predichas por el modelo (0 o 1).\n",
        "        y_prob (array-like or None): Probabilidades predichas para la clase positiva.\n",
        "                                    Si es None, la métrica AUC-ROC no se calcula.\n",
        "\n",
        "    Returns:\n",
        "        dict: Diccionario con las métricas calculadas:\n",
        "            - \"accuracy\": Exactitud.\n",
        "            - \"f1_score\": Puntuación F1.\n",
        "            - \"precision\": Precisión.\n",
        "            - \"recall\": Sensibilidad o recall.\n",
        "            - \"specificity\": Especificidad.\n",
        "            - \"roc_auc\": Área bajo la curva ROC (o None si y_prob es None).\n",
        "    \"\"\"\n",
        "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred, labels=[0,1]).ravel()\n",
        "    return {\n",
        "        \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "        \"f1_score\": f1_score(y_true, y_pred),\n",
        "        \"precision\": precision_score(y_true, y_pred),\n",
        "        \"recall\": recall_score(y_true, y_pred),\n",
        "        \"specificity\": tn / (tn + fp),\n",
        "        \"roc_auc\": roc_auc_score(y_true, y_prob) if y_prob is not None else None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AP-tPiMXZxhX"
      },
      "source": [
        "# **Modelos Machine Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "837VSo6y5IG3"
      },
      "source": [
        "## **Clase para creación de los modelos**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kd5I9SiAxQuQ"
      },
      "outputs": [],
      "source": [
        "class FinancialDistressPredictor:\n",
        "    \"\"\"\n",
        "    Clase para la predicción del estrés financiero (probabilidad de quiebra) en empresas mediante modelos de machine learning.\n",
        "\n",
        "    Esta clase permite:\n",
        "    - Cargar y preprocesar datos financieros desde un archivo Excel.\n",
        "    - Aplicar técnicas de limpieza, escalado y balanceo de clases (SMOTE).\n",
        "    - Entrenar y validar modelos de clasificación como Regresión Logística, SVM o Random Forest.\n",
        "    - Realizar búsqueda de hiperparámetros con validación cruzada.\n",
        "    - Almacenar y reportar métricas de evaluación como accuracy, F1, precision, recall, especificidad y AUC.\n",
        "    - Validar el rendimiento del modelo entrenado en un conjunto de datos externo (otro año o conjunto de empresas).\n",
        "\n",
        "    Atributos:\n",
        "        seed (int): Semilla para reproducibilidad de resultados aleatorios.\n",
        "        model: Modelo de clasificación entrenado.\n",
        "        scaler (MinMaxScaler): Escalador usado para normalizar las variables numéricas.\n",
        "        X (pd.DataFrame): Matriz de variables explicativas originales.\n",
        "        Y (pd.Series): Vector objetivo binario (0: Saludable, 1: Quiebra).\n",
        "        X_scaled (np.ndarray): Matriz escalada de variables explicativas.\n",
        "        empresa_info (pd.DataFrame): Información básica de las empresas (nombre y país).\n",
        "        accuracy (list): Métricas de accuracy por modelo.\n",
        "        f1 (list): Métricas F1-score por modelo.\n",
        "        precision (list): Métricas de precisión por modelo.\n",
        "        recall (list): Métricas de recall (sensibilidad) por modelo.\n",
        "        spec (list): Métricas de especificidad por modelo.\n",
        "        roc_auc (list): Métricas de AUC ROC por modelo.\n",
        "        best_params (dict): Mejores hiperparámetros obtenidos durante la búsqueda.\n",
        "    \"\"\"\n",
        "    def __init__(self, seed=54163312):\n",
        "        self.seed = seed\n",
        "        self.model = None\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.X = None\n",
        "        self.Y = None\n",
        "        self.X_scaled = None\n",
        "        self.empresa_info = None\n",
        "\n",
        "        self.X_test = None\n",
        "        self.X_test_scaled = None\n",
        "        self.Y_test = None\n",
        "        self.empresa_info_test = None\n",
        "\n",
        "        self.accuracy = []\n",
        "        self.f1 = []\n",
        "        self.precision = []\n",
        "        self.recall = []\n",
        "        self.spec = []\n",
        "        self.roc_auc = []\n",
        "        self.best_params = None\n",
        "\n",
        "    def cargar_datos(self, ruta_excel, año=2021, aplicar_smote=True, test_size=0.2):\n",
        "        \"\"\"\n",
        "        Carga, limpia y prepara los datos financieros para el entrenamiento y evaluación de modelos de predicción de quiebra.\n",
        "\n",
        "        Este método lee un archivo Excel con información de empresas, filtra las columnas correspondientes\n",
        "        al año indicado, elimina registros con valores nulos en la variable objetivo, escala los datos y aplica\n",
        "        sobremuestreo SMOTE si se desea. También divide los datos en conjuntos de entrenamiento y prueba.\n",
        "\n",
        "        Parámetros\n",
        "        ----------\n",
        "        ruta_excel : str\n",
        "            Ruta al archivo Excel que contiene los datos financieros.\n",
        "        año : int, opcional\n",
        "            Año de referencia para seleccionar las columnas de variables explicativas. Por defecto es 2021.\n",
        "        aplicar_smote : bool, opcional\n",
        "            Si es True, se aplica SMOTE para balancear las clases en el conjunto de entrenamiento. Por defecto es True.\n",
        "        test_size : float, opcional\n",
        "            Proporción de los datos asignados al conjunto de prueba. Por defecto es 0.2 (20%).\n",
        "\n",
        "        Devuelve\n",
        "        --------\n",
        "        Tuple[pd.DataFrame, pd.Series]\n",
        "            Conjunto de entrenamiento (X, Y) después del preprocesamiento y, si aplica, del sobremuestreo SMOTE.\n",
        "        \"\"\"\n",
        "\n",
        "        df = pd.read_excel(ruta_excel)\n",
        "        empresa_info = df[[\"Nombre empresaAlfabeto latino\", \"País ISO Código\"]]\n",
        "\n",
        "        # Se seleccionan las columnas a partir de la columna 11 en adelante, las primeras 10 son información de la empresa como CNAE, Nombre...\n",
        "        X = df.iloc[:, 10:]\n",
        "        columnas_validas = [col for col in X.columns if str(año) in col]\n",
        "        X = X.loc[:, columnas_validas]\n",
        "\n",
        "        # Se mapea el target a una variables binaria\n",
        "        Y = df['Target'].map({'Saludable': 0, 'Quiebra': 1})\n",
        "\n",
        "        # Se eliminan las empresas que no tengan target\n",
        "        valid_idx = Y.dropna().index\n",
        "        X = X.loc[valid_idx]\n",
        "        Y = Y.loc[valid_idx]\n",
        "        empresa_info = empresa_info.loc[valid_idx]\n",
        "\n",
        "        # Se tratan los valores anómalos y se divide las muestras en training y test\n",
        "        X = self.limpiar_X(X)\n",
        "        X_train, X_test, Y_train, Y_test, info_train, info_test = train_test_split(\n",
        "            X, Y, empresa_info, test_size=test_size, stratify=Y, random_state=self.seed\n",
        "        )\n",
        "\n",
        "        self.X = X_train\n",
        "        self.Y = Y_train\n",
        "        self.empresa_info = info_train\n",
        "\n",
        "        self.X_test = X_test\n",
        "        self.Y_test = Y_test\n",
        "        self.empresa_info_test = info_test\n",
        "\n",
        "        # Se ajustan los pesos del escalador con la muestra de training para luego con estos pesos escalar los de test\n",
        "        self.X_scaled = self.scaler.fit_transform(self.X)\n",
        "        self.X_test_scaled = self.scaler.transform(self.X_test)\n",
        "\n",
        "        if aplicar_smote:\n",
        "            print(\"Aplicando SMOTE sobre clase minoritaria (quiebra)...\")\n",
        "            smote = SMOTE(random_state=self.seed)\n",
        "            self.X_scaled, self.Y = smote.fit_resample(self.X_scaled, self.Y)\n",
        "\n",
        "        joblib.dump(self.scaler, \"scaler_entrenado.joblib\")\n",
        "        return self.X, self.Y\n",
        "\n",
        "    def limpiar_X(self, X):\n",
        "        \"\"\"\n",
        "        Limpieza del dataset numérico.\n",
        "\n",
        "        Este método:\n",
        "        - Selecciona solo columnas numéricas.\n",
        "        - Sustituye los valores infinitos positivos (+inf) por el valor máximo observado en la columna.\n",
        "        - Sustituye los valores infinitos negativos (-inf) y nulos (NaN) por el mínimo valor válido no negativo.\n",
        "\n",
        "        Justificación:\n",
        "        - Los valores +inf representan outliers altos, por lo que imputarlos con el máximo evita distorsión.\n",
        "        - Los valores -inf y NaN se imputan con el mínimo no negativo para no aplastar la escala al escalar con MinMaxScaler.\n",
        "        - Preserva registros que de otro modo serían descartados por tener datos faltantes o erróneos.\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): Variables explicativas.\n",
        "            Y (pd.Series, optional): Etiqueta (target), si está presente.\n",
        "\n",
        "        Returns:\n",
        "            Tuple[pd.DataFrame, pd.Series]: Variables limpias (y etiquetas si se proporcionan).\n",
        "        \"\"\"\n",
        "        X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "        for col in X.columns:\n",
        "            is_pos_inf = X[col] == np.inf\n",
        "            is_neg_inf = X[col] == -np.inf\n",
        "            is_nan = X[col].isna()\n",
        "\n",
        "            # Filtramos los valores válidos\n",
        "            valid_values = X[col][~(is_pos_inf | is_neg_inf | is_nan)]\n",
        "\n",
        "            # Máximo observado en la columna\n",
        "            max_val = valid_values.max()\n",
        "\n",
        "            # Para valores NaNs o -inf se cambia por el valor Min+\n",
        "            min_val = valid_values[valid_values >= 0].min()\n",
        "\n",
        "            # Sustituimos +inf por el máximo\n",
        "            X.loc[is_pos_inf, col] = max_val\n",
        "\n",
        "            # Sustituimos -inf y NaN por el mínimo positivo\n",
        "            X.loc[is_neg_inf | is_nan, col] = min_val\n",
        "\n",
        "        return X\n",
        "\n",
        "\n",
        "    def definir_metricas(self):\n",
        "        \"\"\"\n",
        "        Define un diccionario con las métricas que se utilizarán para evaluar modelos.\n",
        "\n",
        "        Incluye tanto métricas predefinidas por scikit-learn como métricas personalizadas\n",
        "        creadas con `make_scorer`.\n",
        "\n",
        "        Returns:\n",
        "            dict: Diccionario con el nombre de la métrica como clave y el objeto métrico o cadena\n",
        "                  asociada como valor.\n",
        "        \"\"\"\n",
        "        return {\n",
        "            \"accuracy\": \"accuracy\",\n",
        "            \"average_precision\": make_scorer(average_precision_score),\n",
        "            \"f1\": \"f1\",\n",
        "            \"precision\": \"precision\",\n",
        "            \"recall\": make_scorer(recall_score, pos_label=1, labels=[0, 1]),\n",
        "            \"spec\": make_scorer(recall_score, pos_label=0, labels=[0, 1]),\n",
        "            \"roc_auc\": \"roc_auc\"\n",
        "        }\n",
        "\n",
        "    def guardar_scores(self, scores):\n",
        "        \"\"\"\n",
        "        Almacena las métricas de evaluación extraídas de los resultados de validación cruzada.\n",
        "\n",
        "        Convierte las métricas para cada modelo en un formato con media y desviación estándar,\n",
        "        y las agrega a las listas internas correspondientes.\n",
        "\n",
        "        Args:\n",
        "            scores (dict): Diccionario con resultados de evaluación para distintas métricas,\n",
        "                          típicamente obtenidos tras una validación cruzada.\n",
        "        \"\"\"\n",
        "        self.accuracy.append(self._formatear(scores.get(\"test_accuracy\")))\n",
        "        self.f1.append(self._formatear(scores.get(\"test_f1\")))\n",
        "        self.precision.append(self._formatear(scores.get(\"test_precision\")))\n",
        "        self.recall.append(self._formatear(scores.get(\"test_recall\")))\n",
        "        self.spec.append(self._formatear(scores.get(\"test_spec\")))\n",
        "        self.roc_auc.append(self._formatear(scores.get(\"test_roc_auc\")))\n",
        "\n",
        "    def _formatear(self, serie):\n",
        "        \"\"\"\n",
        "        Formatea una serie de valores numéricos en una cadena con media y desviación estándar.\n",
        "\n",
        "        Args:\n",
        "            serie (array-like): Conjunto de valores numéricos.\n",
        "\n",
        "        Returns:\n",
        "            str: Cadena con formato \"media (desviación estándar)\", con 3 decimales.\n",
        "        \"\"\"\n",
        "        return f\"{np.mean(serie):.3f} ({np.std(serie):.3f})\"\n",
        "\n",
        "    def resultados_df(self):\n",
        "        \"\"\"\n",
        "        Crea un DataFrame con las métricas almacenadas para diferentes modelos.\n",
        "\n",
        "        Las filas corresponden a modelos (por ejemplo, Logistic, SVM, RF) y las columnas a las métricas\n",
        "        evaluadas.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame con métricas de evaluación para cada modelo.\n",
        "        \"\"\"\n",
        "        return pd.DataFrame({\n",
        "            \"accuracy\": self.accuracy,\n",
        "            \"f1_score\": self.f1,\n",
        "            \"precision\": self.precision,\n",
        "            \"recall\": self.recall,\n",
        "            \"specificity\": self.spec,\n",
        "            \"roc_auc\": self.roc_auc\n",
        "        }, index=[\"Logistic\", \"SVM\", \"RF\"][:len(self.accuracy)])\n",
        "\n",
        "    def _crear_modelo(self, modelo):\n",
        "        \"\"\"\n",
        "        Crea y ajusta un modelo de clasificación mediante búsqueda aleatoria de hiperparámetros (RandomizedSearchCV).\n",
        "\n",
        "        Soporta los siguientes modelos:\n",
        "        - 'logistic'        → Regresión Logística\n",
        "        - 'svm'             → Máquinas de Vectores de Soporte (SVM)\n",
        "        - 'random_forest'   → Bosque Aleatorio (Random Forest)\n",
        "\n",
        "        Se realiza una búsqueda aleatoria (30 iteraciones) con validación cruzada estratificada estratificada (CV=10),\n",
        "        optimizando el F1-score para encontrar los mejores hiperparámetros del modelo.\n",
        "\n",
        "        Args:\n",
        "            modelo (str): Tipo de modelo a entrenar. Uno de {'logistic', 'svm', 'random_forest'}.\n",
        "\n",
        "        Returns:\n",
        "            sklearn.base.BaseEstimator: Modelo ajustado con los mejores hiperparámetros encontrados.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: Si el nombre del modelo no está reconocido.\n",
        "        \"\"\"\n",
        "        if modelo == 'logistic':\n",
        "            base = LogisticRegression(random_state=self.seed, max_iter=2000)\n",
        "            param_dist = {\n",
        "                'C': [0.01, 0.1, 1, 5, 10],\n",
        "                'penalty': ['l1', 'l2'],\n",
        "                'solver': ['liblinear']\n",
        "            }\n",
        "\n",
        "        elif modelo == 'svm':\n",
        "            base = SVC(probability=True, random_state=self.seed)\n",
        "            param_dist = {\n",
        "                'C': uniform(0.1, 50),\n",
        "                'kernel': ['linear', 'rbf'],\n",
        "                'gamma': uniform(0.001, 1)\n",
        "            }\n",
        "\n",
        "        elif modelo == 'random_forest':\n",
        "            base = RandomForestClassifier(random_state=self.seed)\n",
        "            param_dist = {\n",
        "                'n_estimators': randint(100, 1000),\n",
        "                'max_depth': randint(5, 100),\n",
        "                'min_samples_split': randint(2, 20),\n",
        "                'min_samples_leaf': randint(1, 20),\n",
        "                'max_features': ['sqrt', 'log2', None]\n",
        "            }\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"Modelo no reconocido. Debe ser 'logistic', 'svm' o 'random_forest'.\")\n",
        "\n",
        "        # Optimización mediante búsqueda aleatoria de hiperparámetros\n",
        "        print(f\"Buscando mejores hiperparámetros para {modelo.upper()}...\")\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=self.seed)\n",
        "\n",
        "        search = RandomizedSearchCV(\n",
        "            estimator=base,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=30,\n",
        "            cv=cv,\n",
        "            scoring=\"f1\",\n",
        "            random_state=self.seed,\n",
        "            n_jobs=-1\n",
        "        )\n",
        "\n",
        "        # Entrenamiento del modelo con los datos preprocesados\n",
        "        search.fit(self.X_scaled, self.Y)\n",
        "\n",
        "        print(f\"Mejores parámetros para {modelo.upper()}: {search.best_params_}\")\n",
        "        return search.best_estimator_\n",
        "\n",
        "    def entrenar_modelo(self, modelo='logistic'):\n",
        "        \"\"\"\n",
        "        Entrena un modelo de clasificación utilizando validación cruzada estratificada y guarda las métricas.\n",
        "\n",
        "        El método crea el modelo especificado, define las métricas para evaluación, realiza\n",
        "        validación cruzada con 10 particiones estratificadas, almacena los scores obtenidos y finalmente\n",
        "        ajusta el modelo con todos los datos disponibles.\n",
        "\n",
        "        Args:\n",
        "            modelo (str, opcional): Tipo de modelo a entrenar. Por defecto 'logistic'.\n",
        "\n",
        "        Returns:\n",
        "            None: Los resultados y el modelo entrenado se almacenan en atributos del objeto.\n",
        "        \"\"\"\n",
        "        metricas = self.definir_metricas()\n",
        "        self.model = self._crear_modelo(modelo)\n",
        "        self.best_params = self.model.get_params()\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=self.seed)\n",
        "        scores = cross_validate(self.model, self.X_scaled, self.Y, cv=cv, scoring=metricas)\n",
        "        self.guardar_scores(scores)\n",
        "        self.model.fit(self.X_scaled, self.Y)\n",
        "\n",
        "    def entrenar_modelo_con_params(self, modelo='logistic', params=None):\n",
        "        \"\"\"\n",
        "        Entrena un modelo de clasificación con los hiperparámetros proporcionados y evalúa su rendimiento\n",
        "        mediante validación cruzada estratificada.\n",
        "\n",
        "        Permite reutilizar hiperparámetros óptimos previamente encontrados,\n",
        "        y guarda las métricas obtenidas para su análisis posterior.\n",
        "\n",
        "        Args:\n",
        "            modelo (str): Tipo de modelo a entrenar. Uno de {'logistic', 'svm', 'random_forest'}.\n",
        "            params (dict): Diccionario con los hiperparámetros del modelo. Requiere haber sido previamente ajustado.\n",
        "\n",
        "        Raises:\n",
        "            ValueError: Si el nombre del modelo no es reconocido.\n",
        "        \"\"\"\n",
        "        if modelo == 'logistic':\n",
        "            base = LogisticRegression(**params)\n",
        "        elif modelo == 'svm':\n",
        "            base = SVC(**params)\n",
        "        elif modelo == 'random_forest':\n",
        "            base = RandomForestClassifier(**params)\n",
        "        else:\n",
        "            raise ValueError(\"Modelo no reconocido.\")\n",
        "\n",
        "        self.model = base\n",
        "        metricas = self.definir_metricas()\n",
        "\n",
        "        # Validación cruzada estratificada con 10 particiones\n",
        "        cv = StratifiedKFold(n_splits=10, shuffle=True, random_state=self.seed)\n",
        "\n",
        "        # Evaluación del modelo con validación cruzada\n",
        "        scores = cross_validate(self.model, self.X_scaled, self.Y, cv=cv, scoring=metricas)\n",
        "\n",
        "        # Almacenamiento de resultados de evaluación\n",
        "        self.guardar_scores(scores)\n",
        "\n",
        "        # Entrenamiento final del modelo con todos los datos, de esta manera se guarda el modelo para posteriormente poder validarlo\n",
        "        self.model.fit(self.X_scaled, self.Y)\n",
        "\n",
        "    def validar_modelo(self):\n",
        "        \"\"\"\n",
        "        Valida el modelo entrenado utilizando el conjunto de prueba.\n",
        "\n",
        "        Este método evalúa el rendimiento del modelo sobre los datos de test. Para ello,\n",
        "        limpia y escala el conjunto de test, genera las predicciones y, si el modelo lo permite,\n",
        "        calcula también las probabilidades asociadas a la clase positiva (quiebra).\n",
        "\n",
        "        Devuelve\n",
        "        --------\n",
        "        pd.DataFrame\n",
        "            Un DataFrame con los resultados de la validación, incluyendo:\n",
        "            - 'Real': clase real (0 = saludable, 1 = quiebra)\n",
        "            - 'Prediccion': clase predicha por el modelo\n",
        "            - 'Correcta': booleano indicando si la predicción fue correcta\n",
        "            - 'Probabilidad_Quiebra' (opcional): probabilidad estimada de quiebra si el modelo lo permite\n",
        "\n",
        "        Lanza\n",
        "        -----\n",
        "        ValueError\n",
        "            Si no se han definido los conjuntos `X_test` y `Y_test`, lo que indica que no se ha llamado antes\n",
        "            al método `cargar_datos` con división en test.\n",
        "        \"\"\"\n",
        "        if self.X_test is None or self.Y_test is None:\n",
        "            raise ValueError(\"No se han definido datos de test. Asegúrate de haber cargado los datos con test_split.\")\n",
        "\n",
        "        # Se tratan los valores anómalos y se escala con los pesos de training\n",
        "        X_val = self.limpiar_X(self.X_test.copy())\n",
        "        X_val_scaled = self.scaler.transform(X_val)\n",
        "\n",
        "        y_pred = self.model.predict(X_val_scaled)\n",
        "        y_proba = self.model.predict_proba(X_val_scaled)[:, 1] if hasattr(self.model, \"predict_proba\") else None\n",
        "\n",
        "        resultados = pd.DataFrame({\n",
        "            \"Real\": self.Y_test.values,\n",
        "            \"Prediccion\": y_pred,\n",
        "            \"Correcta\": y_pred == self.Y_test.values\n",
        "        })\n",
        "\n",
        "        if y_proba is not None:\n",
        "            resultados[\"Probabilidad_Quiebra\"] = y_proba\n",
        "\n",
        "        return resultados\n",
        "\n",
        "    def guardar_modelo(self, model_path, scaler_path):\n",
        "        \"\"\"\n",
        "        Guarda en disco el modelo entrenado y el objeto de escalado (scaler) utilizando joblib.\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Ruta del archivo donde se almacenará el modelo entrenado.\n",
        "            scaler_path (str): Ruta del archivo donde se almacenará el scaler utilizado para el preprocesamiento.\n",
        "        \"\"\"\n",
        "        joblib.dump(self.model, model_path)\n",
        "        joblib.dump(self.scaler, scaler_path)\n",
        "\n",
        "    def cargar_modelo(self, model_path, scaler_path):\n",
        "        \"\"\"\n",
        "        Carga desde disco un modelo previamente entrenado y el scaler correspondiente.\n",
        "\n",
        "        Args:\n",
        "            model_path (str): Ruta del archivo que contiene el modelo entrenado.\n",
        "            scaler_path (str): Ruta del archivo que contiene el scaler utilizado previamente.\n",
        "        \"\"\"\n",
        "        self.model = joblib.load(model_path)\n",
        "        self.scaler = joblib.load(scaler_path)\n",
        "\n",
        "    def graficar_importancia_variables(self, modelo, top_n=10, X_val=None, Y_val=None):\n",
        "        \"\"\"\n",
        "        Genera una gráfica con las variables más importantes utilizadas por el modelo entrenado.\n",
        "\n",
        "        La función determina la importancia de las variables según el tipo de modelo:\n",
        "        - Modelos como Random Forest usan `feature_importances_`.\n",
        "        - Modelos lineales como regresión logística usan `coef_`.\n",
        "        - Otros modelos se evalúan mediante `permutation_importance`.\n",
        "\n",
        "        También guarda la lista de variables importantes en un archivo de texto (`variables.txt`).\n",
        "\n",
        "        Args:\n",
        "            modelo (str): Nombre del modelo utilizado (solo se usa para el título de la gráfica y el log).\n",
        "            top_n (int): Número de variables más importantes a mostrar.\n",
        "            X_val (np.ndarray or None): Datos de validación para importancia por permutación (si aplica).\n",
        "            Y_val (np.ndarray or None): Etiquetas de validación para importancia por permutación (si aplica).\n",
        "\n",
        "        Raises:\n",
        "            ValueError: Si el modelo aún no ha sido entrenado.\n",
        "        \"\"\"\n",
        "        if self.model is None:\n",
        "            raise ValueError(\"El modelo no ha sido entrenado aún.\")\n",
        "\n",
        "        # Se obtienen los nombres originales de las variables antes del escalado\n",
        "        nombres_variables = self.X.columns\n",
        "\n",
        "        # Si el modelo tiene el atributo feature_importances_ (como los árboles)\n",
        "        if hasattr(self.model, 'feature_importances_'):\n",
        "            print(\"Importancia basada en feature_importances_\")\n",
        "            importancias = self.model.feature_importances_\n",
        "\n",
        "        # Si el modelo tiene coef_ (como los modelos lineales)\n",
        "        elif hasattr(self.model, 'coef_'):\n",
        "            print(\"Importancia basada en coef_\")\n",
        "            importancias = np.abs(self.model.coef_).flatten()\n",
        "\n",
        "        # Para otros modelos, se calcula la importancia mediante permutación\n",
        "        else:\n",
        "            print(\"Calculando importancia por permutación (modelo no interpretable directamente)...\")\n",
        "\n",
        "            # Si no se han pasado datos de validación, se usan los de entrenamiento\n",
        "            if X_val is None or Y_val is None:\n",
        "                X_val = self.X_scaled\n",
        "                Y_val = self.Y\n",
        "\n",
        "            # Calcula la importancia de cada variable perturbando su orden\n",
        "            result = permutation_importance(\n",
        "                self.model, X_val, Y_val,\n",
        "                n_repeats=10,\n",
        "                random_state=self.seed,\n",
        "                n_jobs=-1\n",
        "            )\n",
        "            importancias = result.importances_mean\n",
        "\n",
        "        # Selecciona los índices de las top_n variables más importantes\n",
        "        top_indices = np.argsort(importancias)[-top_n:][::-1]\n",
        "        top_nombres = [nombres_variables[i] for i in top_indices]\n",
        "        top_importancias = importancias[top_indices]\n",
        "\n",
        "        # Genera la gráfica de barras\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.barh(top_nombres[::-1], top_importancias[::-1])\n",
        "        plt.xlabel(\"Importancia\")\n",
        "        plt.title(f\"Top {top_n} variables más importantes - {modelo.upper()}\")\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "        # Guarda las variables e importancias en un archivo de texto\n",
        "        with open(\"variables.txt\", \"a\", encoding=\"utf-8\") as f:\n",
        "            f.write(f\"\\nModelo: {modelo.upper()}\\n\")\n",
        "            f.write(f\"{'Variable':<40} {'Importancia':>10}\\n\")\n",
        "            f.write(\"-\" * 52 + \"\\n\")\n",
        "            for nombre, importancia in zip(top_nombres, top_importancias):\n",
        "                f.write(f\"{nombre:<40} {importancia:.4f}\\n\")\n",
        "            f.write(\"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KB1s0TFw3ue"
      },
      "source": [
        "## **Red neuronal, siguiendo la arquitectura MLP**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WSkXUr79g9jK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "class MLPFinancialNet(nn.Module):\n",
        "    \"\"\"\n",
        "    Modelo de red neuronal tipo Perceptrón Multicapa (MLP) para clasificación binaria\n",
        "    de estrés financiero. Recibe un número de dimensiones de entrada, una estructura\n",
        "    de capas ocultas y un valor de dropout.\n",
        "\n",
        "    Args:\n",
        "        input_dim (int): Número de características de entrada.\n",
        "        hidden_dims (tuple): Tamaño de cada capa oculta. Ej. (16,) o (32, 16).\n",
        "        dropout (float): Probabilidad de desactivación (regularización).\n",
        "    \"\"\"\n",
        "    def __init__(self, input_dim: int, hidden_dims=(32, 16, ), dropout: float = 0.1):\n",
        "        super().__init__()\n",
        "        layers = []\n",
        "        in_dim = input_dim\n",
        "        for h in hidden_dims:\n",
        "            layers += [nn.Linear(in_dim, h), nn.ReLU(), nn.Dropout(dropout)]\n",
        "            in_dim = h\n",
        "        layers += [nn.Linear(in_dim, 1)]\n",
        "        self.feature_extractor = nn.Sequential(*layers)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x, raw_output=False):\n",
        "        logits = self.feature_extractor(x).squeeze()\n",
        "        probs = self.sigmoid(logits)\n",
        "        return probs if raw_output else (probs >= 0.5).float()\n",
        "\n",
        "\n",
        "class FinancialMLPTrainer:\n",
        "    \"\"\"\n",
        "    Clase para entrenar y evaluar un modelo MLP sobre datos financieros con validación\n",
        "    cruzada y posibilidad de aplicar SMOTE y escalado.\n",
        "\n",
        "    Args:\n",
        "        ruta_excel (str): Ruta al archivo Excel con los datos.\n",
        "        año (int): Año base de los datos financieros.\n",
        "        scaler: Instancia de escalador (por defecto MinMaxScaler).\n",
        "        aplicar_scaler (bool): Si True, aplica escalado MinMax.\n",
        "        aplicar_smote (bool): Si True, aplica sobremuestreo con SMOTE.\n",
        "        seed (int): Semilla para reproducibilidad.\n",
        "    \"\"\"\n",
        "    def __init__(self, ruta_excel, año=2021, aplicar_scaler=False, aplicar_smote=False, seed=54163312, test_size=0.2):\n",
        "        self.seed = seed\n",
        "        self.año = año\n",
        "        self.aplicar_scaler = aplicar_scaler\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.aplicar_smote = aplicar_smote\n",
        "        self.test_size = test_size\n",
        "        self.df = pd.read_excel(ruta_excel)\n",
        "        self.X_train, self.X_test, self.Y_train, self.Y_test = self._preprocesar()\n",
        "        self.fold_metrics = []\n",
        "\n",
        "    def limpiar_X(self, X):\n",
        "        \"\"\"\n",
        "        Limpieza del dataset numérico.\n",
        "        Sustituye +inf por el máximo observado y -inf/NaN por el mínimo positivo.\n",
        "\n",
        "        Args:\n",
        "            X (pd.DataFrame): DataFrame con variables explicativas.\n",
        "\n",
        "        Returns:\n",
        "            pd.DataFrame: DataFrame limpio solo con variables numéricas.\n",
        "        \"\"\"\n",
        "        X = X.select_dtypes(include=[np.number])\n",
        "\n",
        "        for col in X.columns:\n",
        "            is_pos_inf = X[col] == np.inf\n",
        "            is_neg_inf = X[col] == -np.inf\n",
        "            is_nan = X[col].isna()\n",
        "\n",
        "            valid_values = X[col][~(is_pos_inf | is_neg_inf | is_nan)]\n",
        "            max_val = valid_values.max()\n",
        "            min_val = valid_values[valid_values >= 0].min()\n",
        "\n",
        "            X.loc[is_pos_inf, col] = max_val\n",
        "            X.loc[is_neg_inf | is_nan, col] = min_val\n",
        "\n",
        "        return X\n",
        "\n",
        "    def _preprocesar(self):\n",
        "        \"\"\"\n",
        "        Realiza el preprocesamiento completo del conjunto de datos para entrenamiento y validación.\n",
        "\n",
        "        Este método filtra las columnas del DataFrame `self.df` correspondientes al año especificado,\n",
        "        codifica la variable objetivo, elimina registros con valores nulos, limpia los datos con el\n",
        "        método `limpiar_X`, divide en conjuntos de entrenamiento y prueba, y aplica escalado y SMOTE\n",
        "        si están activados.\n",
        "\n",
        "        Devuelve\n",
        "        --------\n",
        "        Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]\n",
        "            - X_train: Variables explicativas del conjunto de entrenamiento\n",
        "            - X_test: Variables explicativas del conjunto de test\n",
        "            - Y_train: Etiquetas del conjunto de entrenamiento\n",
        "            - Y_test: Etiquetas del conjunto de test\n",
        "\n",
        "        Notas\n",
        "        -----\n",
        "        - El escalado se realiza solo si `self.aplicar_scaler` es True.\n",
        "        - El sobremuestreo SMOTE se aplica solo si `self.aplicar_smote` es True.\n",
        "        - Las variables objetivo se codifican como: 'Saludable' → 0, 'Quiebra' → 1.\n",
        "        - El procedimiento es igual que en el caso de los modelos anteriores\n",
        "        \"\"\"\n",
        "        X = self.df.iloc[:, 10:]\n",
        "        columnas_validas = [col for col in X.columns if str(self.año) in col]\n",
        "        X = X.loc[:, columnas_validas]\n",
        "        Y = self.df['Target'].map({'Saludable': 0, 'Quiebra': 1})\n",
        "        valid_idx = Y.dropna().index\n",
        "        X, Y = X.loc[valid_idx], Y.loc[valid_idx]\n",
        "        X = self.limpiar_X(X)\n",
        "        X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "            X, Y, test_size=self.test_size, stratify=Y, random_state=self.seed\n",
        "        )\n",
        "        if self.aplicar_scaler:\n",
        "            X_train = self.scaler.fit_transform(X_train)\n",
        "            X_test = self.scaler.transform(X_test)\n",
        "        if self.aplicar_smote:\n",
        "            X_train, Y_train = SMOTE(random_state=self.seed).fit_resample(X_train, Y_train)\n",
        "        return np.array(X_train), np.array(X_test), np.array(Y_train), np.array(Y_test)\n",
        "\n",
        "\n",
        "    def entrenar_kfold(self, n_splits=10, lr=0.01, hidden_dims=(16,), dropout=0.1, max_epochs=400, patience=30):\n",
        "        \"\"\"\n",
        "        Entrenamiento de una red neuronal MLP con validación cruzada estratificada (Stratified K-Fold).\n",
        "\n",
        "        Este método:\n",
        "        - Divide los datos en `n_splits` pliegues estratificados (con distribución de clases similar en cada fold).\n",
        "        - Entrena una red neuronal para cada fold utilizando el conjunto de entrenamiento.\n",
        "        - Evalúa en el conjunto de validación en cada época.\n",
        "        - Guarda el mejor modelo por fold usando Early Stopping basado en la pérdida de validación.\n",
        "        - Calcula y almacena métricas de desempeño como accuracy, precision, recall, F1, especificidad y AUC-ROC.\n",
        "\n",
        "        Args:\n",
        "            n_splits (int): Número de pliegues para validación cruzada (por defecto 10).\n",
        "            lr (float): Tasa de aprendizaje para el optimizador Adam.\n",
        "            hidden_dims (tuple): Dimensiones de las capas ocultas (ej. (32, 16) para dos capas).\n",
        "            dropout (float): Probabilidad de dropout aplicada tras cada capa oculta.\n",
        "            max_epochs (int): Número máximo de épocas de entrenamiento.\n",
        "            patience (int): Nº de épocas sin mejora en la pérdida de validación antes de detener el entrenamiento (early stopping).\n",
        "\n",
        "        Returns:\n",
        "            None. Las métricas por fold se almacenan en `self.fold_metrics`, y el último modelo entrenado se guarda en `self.model`.\n",
        "        \"\"\"\n",
        "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=self.seed)\n",
        "\n",
        "        # Recorremos cada fold de la validación cruzada\n",
        "        for fold, (train_idx, val_idx) in enumerate(skf.split(self.X_train, self.Y_train)):\n",
        "            print(f\"\\nFold {fold + 1}/{n_splits}\")\n",
        "\n",
        "            # Seleccionamos los datos de entrenamiento y validación según los índices del fold actual\n",
        "            X_train, X_val = self.X_train[train_idx], self.X_train[val_idx]\n",
        "            y_train, y_val = self.Y_train[train_idx], self.Y_train[val_idx]\n",
        "\n",
        "            # Convertimos los datos a tensores de PyTorch (float32 requerido por el modelo)\n",
        "            X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "            X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
        "            y_train_tensor = torch.tensor(np.array(y_train), dtype=torch.float32)\n",
        "            y_val_tensor = torch.tensor(np.array(y_val), dtype=torch.float32)\n",
        "\n",
        "            # Inicializamos el modelo MLP, el optimizador Adam y la función de pérdida binaria\n",
        "            model = MLPFinancialNet(X_train.shape[1], hidden_dims, dropout)\n",
        "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "            criterion = nn.BCELoss()\n",
        "\n",
        "            # Variables para controlar el early stopping\n",
        "            best_loss = float('inf')\n",
        "            best_model = None\n",
        "            epochs_no_improve = 0\n",
        "\n",
        "            # Bucle de entrenamiento por épocas\n",
        "            for epoch in range(max_epochs):\n",
        "                model.train()\n",
        "                optimizer.zero_grad()\n",
        "                output = model(X_train_tensor, raw_output=True)\n",
        "                loss = criterion(output, y_train_tensor) # Cálculo de pérdida\n",
        "                loss.backward() # Backpropagation\n",
        "                optimizer.step() # Actualización de pesos\n",
        "\n",
        "                model.eval()\n",
        "                with torch.no_grad():\n",
        "                    val_output = model(X_val_tensor, raw_output=True)\n",
        "                    val_loss = criterion(val_output, y_val_tensor).item()\n",
        "                    val_preds = (val_output >= 0.5).float() # Umbral de clasificación\n",
        "                    val_acc = (val_preds == y_val_tensor).float().mean().item()\n",
        "\n",
        "                # Mostrar métricas cada 10 épocas\n",
        "                if epoch % 10 == 0:\n",
        "                    print(f\"Epoch {epoch} | Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.4f}\")\n",
        "\n",
        "                if val_loss < best_loss - 1e-4:\n",
        "                    best_loss = val_loss\n",
        "                    best_model = model.state_dict()\n",
        "                    epochs_no_improve = 0\n",
        "                else:\n",
        "                    epochs_no_improve += 1\n",
        "\n",
        "                if epochs_no_improve >= patience:\n",
        "                    print(\"Early stopping.\")\n",
        "                    break\n",
        "\n",
        "            # Cargamos el mejor modelo guardado en este fold\n",
        "            model.load_state_dict(best_model)\n",
        "            model.eval()\n",
        "\n",
        "            # Predicción en el conjunto de validación\n",
        "            with torch.no_grad():\n",
        "                y_prob = model(X_val_tensor, raw_output=True).numpy()\n",
        "                y_pred = (y_prob >= 0.5).astype(int)\n",
        "                y_true = y_val_tensor.numpy()\n",
        "\n",
        "            tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "            specificity = tn / (tn + fp)\n",
        "\n",
        "            metrics = {\n",
        "                \"accuracy\": accuracy_score(y_true, y_pred),\n",
        "                \"precision\": precision_score(y_true, y_pred),\n",
        "                \"recall\": recall_score(y_true, y_pred),\n",
        "                \"specificity\": specificity,\n",
        "                \"f1_score\": f1_score(y_true, y_pred),\n",
        "                \"roc_auc\": roc_auc_score(y_true, y_prob)\n",
        "            }\n",
        "\n",
        "            print(f\"Fold {fold + 1} Metrics:\", metrics)\n",
        "\n",
        "            # Guardamos las métricas y el modelo entrenado\n",
        "            self.fold_metrics.append(metrics)\n",
        "            self.model = model\n",
        "            self.resumen_metricas()\n",
        "\n",
        "    def resumen_metricas(self):\n",
        "        \"\"\"\n",
        "        Calcula y muestra el promedio de las métricas obtenidas en la validación cruzada.\n",
        "\n",
        "        Esta función toma las métricas almacenadas en `self.fold_metrics` (lista o dict con resultados\n",
        "        por cada fold), calcula el promedio para cada métrica, imprime el resumen y guarda el resultado\n",
        "        en el atributo `self.mean_cv_metrics` para uso posterior.\n",
        "\n",
        "        Returns:\n",
        "            dict: Diccionario con el promedio de las métricas de validación cruzada.\n",
        "        \"\"\"\n",
        "        df = pd.DataFrame(self.fold_metrics)\n",
        "        resumen = df.mean().round(3)\n",
        "        print(\"\\nPromedio de métricas por validación cruzada:\")\n",
        "        print(resumen)\n",
        "        self.mean_cv_metrics = resumen.to_dict()\n",
        "        return self.mean_cv_metrics\n",
        "\n",
        "    def resumen_metricas(self):\n",
        "        \"\"\"\n",
        "        Calcula y muestra el promedio y desviación estándar de las métricas obtenidas en la validación cruzada.\n",
        "        \"\"\"\n",
        "        df = pd.DataFrame(self.fold_metrics)\n",
        "        resumen = df.agg(['mean', 'std']).T.round(3)\n",
        "        resumen.columns = ['media', 'std']\n",
        "        resumen['media (std)'] = resumen.apply(lambda row: f\"{row['media']:.3f} ({row['std']:.3f})\", axis=1)\n",
        "\n",
        "        print(\"\\nResumen de métricas por validación cruzada:\")\n",
        "        print(resumen[['media (std)']])\n",
        "\n",
        "        self.mean_cv_metrics = resumen.to_dict(orient='index')\n",
        "        return self.mean_cv_metrics\n",
        "\n",
        "    def evaluar_test(self):\n",
        "        \"\"\"\n",
        "        Evalúa el rendimiento del modelo entrenado sobre el conjunto de test.\n",
        "\n",
        "        Este método convierte los datos de test a tensores de PyTorch, realiza predicciones\n",
        "        (probabilidades y clases binarias), y calcula métricas de clasificación utilizando una\n",
        "        función externa (`calcular_metricas_validacion`). Imprime por pantalla los resultados\n",
        "        de la evaluación (accuracy, F1-score, AUC, etc.).\n",
        "\n",
        "        \"\"\"\n",
        "        X_tensor = torch.tensor(self.X_test, dtype=torch.float32)\n",
        "        y_true = self.Y_test\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            y_prob = self.model(X_tensor, raw_output=True).squeeze().numpy()\n",
        "            y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "        # Usa la función externa para calcular las métricas\n",
        "        metricas = calcular_metricas_validacion(y_true, y_pred, y_prob)\n",
        "\n",
        "        # Imprime las métricas formateadas\n",
        "        print(\"\\nEvaluación del conjunto de test:\")\n",
        "        for nombre, valor in metricas.items():\n",
        "            if valor is not None:\n",
        "                print(f\"  {nombre.capitalize():<12}: {valor:.3f}\")\n",
        "            else:\n",
        "                print(f\"  {nombre.capitalize():<12}: N/A\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbTCCWurZYJx"
      },
      "source": [
        "## Función para entrenar y validar los distintos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CCfxheHViXd"
      },
      "outputs": [],
      "source": [
        "roc_data = {}\n",
        "\n",
        "def entrenar_y_validar_modelos(ruta_train, año=2021, aplicar_smote=False, test_size=0.2,\n",
        "                               hiperparametros_predefinidos=None, sufijo_experimento=\"\",\n",
        "                               modelos=['logistic', 'svm', 'random_forest', 'ann'],\n",
        "                               titulo_graficas=\"Curvas ROC comparativas por modelo\"):\n",
        "    \"\"\"\n",
        "    Entrena y evalúa diferentes modelos de predicción de quiebra financiera.\n",
        "\n",
        "    Este método permite entrenar modelos tradicionales (Logistic Regression, SVM, Random Forest)\n",
        "    o una red neuronal (ANN) a partir de datos históricos. Realiza validación, calcula métricas,\n",
        "    genera curvas ROC y muestra matrices de confusión. Los resultados se acumulan globalmente\n",
        "    en `roc_data`.\n",
        "\n",
        "    Parámetros\n",
        "    ----------\n",
        "    ruta_train : str\n",
        "        Ruta al archivo Excel con los datos de entrenamiento.\n",
        "    año : int\n",
        "        Año para filtrar las variables financieras.\n",
        "    aplicar_smote : bool\n",
        "        Si es True, se aplica SMOTE al conjunto de entrenamiento.\n",
        "    test_size : float\n",
        "        Proporción del conjunto de test (por defecto 0.2).\n",
        "    hiperparametros_predefinidos : dict or None\n",
        "        Diccionario con hiperparámetros por modelo. Si se proporciona, se usan directamente.\n",
        "    sufijo_experimento : str\n",
        "        Sufijo para nombrar archivos y claves de resultados (por ejemplo \"_v1\").\n",
        "    modelos : list\n",
        "        Lista de modelos a entrenar. Opciones válidas: 'logistic', 'svm', 'random_forest', 'ann'.\n",
        "    titulo_graficas : str\n",
        "        Título general para las gráficas ROC generadas.\n",
        "\n",
        "    Retorna\n",
        "    -------\n",
        "    dict\n",
        "        Diccionario con los hiperparámetros utilizados/optimizados por modelo.\n",
        "    \"\"\"\n",
        "    global roc_data\n",
        "\n",
        "    validaciones = {}\n",
        "    hiperparametros_entrenados = {}\n",
        "    curvas_roc = {}\n",
        "\n",
        "    # Abrir archivo para registrar todas las métricas en texto, uno por cada experimento\n",
        "    with open(f\"metrics_test{sufijo_experimento}.txt\", \"w\", encoding=\"utf-8\") as f_out:\n",
        "\n",
        "        # Por cada modelo se crea una clase\n",
        "        for modelo in modelos:\n",
        "\n",
        "            print(f\"\\nEntrenando modelo: {modelo.upper()}\")\n",
        "\n",
        "            if modelo == \"ann\":\n",
        "                # Instancia el trainer para la red neuronal (MLP)\n",
        "                # Se le pasa la ruta del Excel, el año de análisis, y configuraciones como SMOTE y scaler\n",
        "                ann_trainer = FinancialMLPTrainer(ruta_excel=ruta_train, año=año,\n",
        "                                                  aplicar_scaler=True, aplicar_smote=aplicar_smote,\n",
        "                                                  seed=54163312, test_size=test_size)\n",
        "\n",
        "                # Entrena la red neuronal con validación cruzada K-Fold\n",
        "                # Arquitectura: 2 capas ocultas con 32 y 16 neuronas, y dropout del 10%\n",
        "                ann_trainer.entrenar_kfold(n_splits=5, hidden_dims=(32, 16), dropout=0.1)\n",
        "\n",
        "                # Evalúa el modelo final sobre el conjunto de test (muestra métricas en consola)\n",
        "                ann_trainer.evaluar_test()\n",
        "\n",
        "                # Prepara los datos de test para pasarlos por el modelo (formato tensor)\n",
        "                X_tensor = torch.tensor(ann_trainer.X_test, dtype=torch.float32)\n",
        "\n",
        "                # Convierte las probabilidades en clases binarias (0 o 1) con umbral 0.5\n",
        "                y_true = ann_trainer.Y_test\n",
        "\n",
        "                # Cambia el modelo a modo evaluación (desactiva dropout, etc.)\n",
        "                ann_trainer.model.eval()\n",
        "\n",
        "                # Hace predicciones sin calcular gradientes (más eficiente)\n",
        "                with torch.no_grad():\n",
        "                    # Obtiene las probabilidades de predicción\n",
        "                    y_prob = ann_trainer.model(X_tensor, raw_output=True).squeeze().numpy()\n",
        "                    y_pred = (y_prob >= 0.5).astype(int)\n",
        "\n",
        "                # Calcula los valores necesarios para construir la curva ROC\n",
        "                fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
        "                roc_auc = auc(fpr, tpr)\n",
        "                clave = f\"{modelo}_{año}{sufijo_experimento}\"\n",
        "\n",
        "                # Guarda la curva ROC en el diccionario global para graficarla más tarde\n",
        "                roc_data[clave] = {\n",
        "                    \"fpr\": fpr.tolist(),\n",
        "                    \"tpr\": tpr.tolist(),\n",
        "                    \"thresholds\": thresholds.tolist(),\n",
        "                    \"auc\": roc_auc\n",
        "                }\n",
        "                curvas_roc[modelo] = (fpr, tpr, roc_auc)\n",
        "\n",
        "                # Calcula las métricas de clasificación: accuracy, precision, recall, F1, AUC...\n",
        "                metricas_val = calcular_metricas_validacion(y_true, y_pred, y_prob)\n",
        "\n",
        "                # Guarda los resultados y métricas en el diccionario de validaciones\n",
        "                df_ann_resultado = pd.DataFrame({\n",
        "                    \"Real\": y_true,\n",
        "                    \"Prediccion\": y_pred,\n",
        "                    \"Probabilidad_Quiebra\": y_prob\n",
        "                })\n",
        "                validaciones[modelo] = {\n",
        "                    \"resultados\": df_ann_resultado,\n",
        "                    \"metrics_val\": metricas_val,\n",
        "                    \"metrics_train\": None\n",
        "                }\n",
        "\n",
        "                # Se guardan las metricas en el archivo\n",
        "                for k, v in metricas_val.items():\n",
        "                    f_out.write(f\"{modelo.upper()} - {k}: {v:.3f}\\n\")\n",
        "                f_out.write(\"\\n\")\n",
        "\n",
        "\n",
        "                # Se muestra la matriz de confusión del modelo en ese experimento y se guardan las metricas en el diccionario\n",
        "                mostrar_matriz_confusion(y_true, y_pred, modelo, title=f\"{titulo_graficas} - {modelo.upper()}\")\n",
        "            else:\n",
        "                # Instancia el predictor y carga los datos\n",
        "                predictor = FinancialDistressPredictor(seed=54163312)\n",
        "                predictor.cargar_datos(ruta_excel=ruta_train, año=año, aplicar_smote=aplicar_smote, test_size=test_size)\n",
        "\n",
        "                # Si hay hiperparámetros predefinidos para este modelo, los usa directamente, si no entrena el modelo haciendo búsqueda de hiperparámetros automáticamente\n",
        "                if hiperparametros_predefinidos and modelo in hiperparametros_predefinidos:\n",
        "                    print(f\"Usando hiperparámetros predefinidos para {modelo.upper()}\")\n",
        "                    predictor.entrenar_modelo_con_params(modelo=modelo, params=hiperparametros_predefinidos[modelo])\n",
        "                else:\n",
        "                    predictor.entrenar_modelo(modelo=modelo)\n",
        "\n",
        "                hiperparametros_entrenados[modelo] = predictor.best_params\n",
        "\n",
        "                # Validación sobre el conjunto de test, predice y devuelve un DataFrame con resultados\n",
        "                print(f\"Validando modelo {modelo.upper()} con los datos de test\")\n",
        "                resultados_val = predictor.validar_modelo()\n",
        "\n",
        "                # Extrae las variables reales, predichas y probabilidades (si están disponibles)\n",
        "                y_true = resultados_val[\"Real\"].values\n",
        "                y_pred = resultados_val[\"Prediccion\"].values\n",
        "                y_prob = resultados_val.get(\"Probabilidad_Quiebra\", None)\n",
        "                if y_prob is not None:\n",
        "                    y_prob = y_prob.values\n",
        "\n",
        "                # Calcula las métricas de evaluación: accuracy, precision, recall, F1, AUC, etc.\n",
        "                metricas_val = calcular_metricas_validacion(y_true, y_pred, y_prob)\n",
        "\n",
        "                # Guarda los resultados y métricas en el diccionario global de validaciones\n",
        "                validaciones[modelo] = {\n",
        "                    \"resultados\": resultados_val,\n",
        "                    \"metrics_val\": metricas_val,\n",
        "                    \"metrics_train\": predictor.resultados_df().iloc[-1] if not predictor.resultados_df().empty else None\n",
        "                }\n",
        "\n",
        "                # Imprime y guarda las métricas en el archivo\n",
        "                print(f\"Métricas de validación para {modelo.upper()}:\")\n",
        "                for k, v in metricas_val.items():\n",
        "                    print(f\"  {k}: {v:.3f}\" if v is not None else f\"  {k}: N/A\")\n",
        "                    f_out.write(f\"{modelo.upper()} - {k}: {v:.3f}\\n\" if v is not None else f\"{modelo.upper()} - {k}: N/A\\n\")\n",
        "                f_out.write(\"\\n\")\n",
        "\n",
        "                # Visualiza la matriz de confusión para este modelo y experimento\n",
        "                mostrar_matriz_confusion(y_true, y_pred, modelo, title=f\"{titulo_graficas} - {modelo.upper()}\")\n",
        "\n",
        "                # Si se dispone de probabilidades, calcula y guarda la curva ROC\n",
        "                if y_prob is not None:\n",
        "                    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
        "                    roc_auc = auc(fpr, tpr)\n",
        "                    clave = f\"{modelo}_{año}{sufijo_experimento}\"\n",
        "                    curvas_roc[modelo] = (fpr, tpr, roc_auc)\n",
        "                    roc_data[clave] = {\n",
        "                        \"fpr\": fpr.tolist(),\n",
        "                        \"tpr\": tpr.tolist(),\n",
        "                        \"thresholds\": thresholds.tolist(),\n",
        "                        \"auc\": roc_auc\n",
        "                    }\n",
        "\n",
        "    graficar_curvas_roc_comparativas(validaciones, title=titulo_graficas)\n",
        "\n",
        "    return hiperparametros_entrenados\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hiperparámetros"
      ],
      "metadata": {
        "id": "ywGmvAxGB9Se"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se ha creado un diccionario con todos lo parámetros que tienen en cuenta los modelos, de manera que en futuras ejecuciones no se tengan que buscar nuevamente puesto ya han sido obtenidos."
      ],
      "metadata": {
        "id": "7YAVIBpVVRRF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hiperparametros = {\n",
        "    \"logistic\": {\n",
        "        \"C\": 10,\n",
        "        \"class_weight\": None,\n",
        "        \"dual\": False,\n",
        "        \"fit_intercept\": True,\n",
        "        \"intercept_scaling\": 1,\n",
        "        \"l1_ratio\": None,\n",
        "        \"max_iter\": 2000,\n",
        "        \"multi_class\": \"deprecated\",\n",
        "        \"n_jobs\": None,\n",
        "        \"penalty\": \"l1\",\n",
        "        \"random_state\": 54163312,\n",
        "        \"solver\": \"liblinear\",\n",
        "        \"tol\": 0.0001,\n",
        "        \"verbose\": 0,\n",
        "        \"warm_start\": False\n",
        "    },\n",
        "    \"svm\": {\n",
        "        \"C\": 46.70810116812693,\n",
        "        \"break_ties\": False,\n",
        "        \"cache_size\": 200,\n",
        "        \"class_weight\": None,\n",
        "        \"coef0\": 0.0,\n",
        "        \"decision_function_shape\": \"ovr\",\n",
        "        \"degree\": 3,\n",
        "        \"gamma\": 0.9654088998029037,\n",
        "        \"kernel\": \"rbf\",\n",
        "        \"max_iter\": -1,\n",
        "        \"probability\": True,\n",
        "        \"random_state\": 54163312,\n",
        "        \"shrinking\": True,\n",
        "        \"tol\": 0.001,\n",
        "        \"verbose\": False\n",
        "    },\n",
        "    \"random_forest\": {\n",
        "        \"bootstrap\": True,\n",
        "        \"ccp_alpha\": 0.0,\n",
        "        \"class_weight\": None,\n",
        "        \"criterion\": \"gini\",\n",
        "        \"max_depth\": 87,\n",
        "        \"max_features\": \"sqrt\",\n",
        "        \"max_leaf_nodes\": None,\n",
        "        \"max_samples\": None,\n",
        "        \"min_impurity_decrease\": 0.0,\n",
        "        \"min_samples_leaf\": 7,\n",
        "        \"min_samples_split\": 7,\n",
        "        \"min_weight_fraction_leaf\": 0.0,\n",
        "        \"monotonic_cst\": None,\n",
        "        \"n_estimators\": 589,\n",
        "        \"n_jobs\": None,\n",
        "        \"oob_score\": False,\n",
        "        \"random_state\": 54163312,\n",
        "        \"verbose\": 0,\n",
        "        \"warm_start\": False\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "WZTefyfBB6ly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dql0ayzAxuXv"
      },
      "source": [
        "## **Entrenamiento del modelo con datos financieros únicamente**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pbw9yx9FGSu"
      },
      "outputs": [],
      "source": [
        "hiperparametros2 = entrenar_y_validar_modelos(\n",
        "    ruta_train='/content/training.xlsx',\n",
        "    año=2021,\n",
        "    aplicar_smote=False,\n",
        "    hiperparametros_predefinidos=hiperparametros,\n",
        "    titulo_graficas=\"Experimento con datos originales\",\n",
        "    sufijo_experimento=\"_exp1\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qfJG1GNxyXd"
      },
      "source": [
        "## **Entrenamiento del modelo con datos financieros únicamente aplicando SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ypWn-Rcc11aE"
      },
      "outputs": [],
      "source": [
        "entrenar_y_validar_modelos(\n",
        "    ruta_train='/content/training.xlsx',\n",
        "    año=2021,\n",
        "    aplicar_smote=True,\n",
        "    hiperparametros_predefinidos=hiperparametros,\n",
        "    titulo_graficas=\"Experimento con datos originales aplicando SMOTE\",\n",
        "    sufijo_experimento=\"_exp2\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2q8Eq3oxPWE"
      },
      "source": [
        "## **Entrenamiento del modelo con variables innovativas**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "yzl9xk6QS4iU"
      },
      "outputs": [],
      "source": [
        "entrenar_y_validar_modelos(\n",
        "    ruta_train='/content/trainingInnovacion.xlsx',\n",
        "    año=2021,\n",
        "    aplicar_smote=False,\n",
        "    hiperparametros_predefinidos=hiperparametros,\n",
        "    titulo_graficas=\"Experimento con variables innovadoras\",\n",
        "    sufijo_experimento=\"_exp3\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z58cVhvGxU6A"
      },
      "source": [
        "## **Entrenamiento del modelo con variables innovativas aplicando SMOTE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "BWhSHPYIS4wX"
      },
      "outputs": [],
      "source": [
        "entrenar_y_validar_modelos(\n",
        "    ruta_train='/content/trainingInnovacion.xlsx',\n",
        "    año=2021,\n",
        "    aplicar_smote=True,\n",
        "    hiperparametros_predefinidos=hiperparametros,\n",
        "    titulo_graficas=\"Experimento con variables innovadoras aplicando SMOTE\",\n",
        "    sufijo_experimento=\"_exp4\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKTO2hoRN1Wj"
      },
      "source": [
        "# Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5934fWErNt_f"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "\n",
        "\n",
        "class ClusteringAnalyzer:\n",
        "    \"\"\"\n",
        "    Clase para realizar análisis de agrupamiento (clustering) sobre datos financieros de empresas.\n",
        "\n",
        "    Esta clase permite cargar un archivo Excel, filtrar y escalar datos, aplicar reducción de dimensionalidad\n",
        "    con PCA, ejecutar KMeans, visualizar los resultados, compararlos con una variable objetivo y exportarlos.\n",
        "\n",
        "    Atributos\n",
        "    ----------\n",
        "    df : pd.DataFrame\n",
        "        Conjunto de datos cargado desde el archivo Excel.\n",
        "    year_column_filter : str\n",
        "        Año para filtrar las columnas financieras (por defecto \"2021\").\n",
        "    n_clusters : int\n",
        "        Número de clústeres a generar con KMeans.\n",
        "    scaler : sklearn.preprocessing.MinMaxScaler\n",
        "        Escalador usado para normalizar los datos.\n",
        "    kmeans : sklearn.cluster.KMeans or None\n",
        "        Instancia del modelo KMeans (una vez ejecutado).\n",
        "    X_scaled : np.ndarray or None\n",
        "        Datos numéricos preprocesados y escalados.\n",
        "    cluster_labels : np.ndarray or None\n",
        "        Etiquetas asignadas por el algoritmo KMeans.\n",
        "    df_clustered : pd.DataFrame or None\n",
        "        DataFrame original con una columna adicional \"Cluster\".\n",
        "    X_pca : np.ndarray or None\n",
        "        Datos proyectados en 2 dimensiones usando PCA.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ruta_excel, year_column_filter=\"2021\", n_clusters=3):\n",
        "        self.df = pd.read_excel(ruta_excel)\n",
        "        self.year_column_filter = year_column_filter\n",
        "        self.n_clusters = n_clusters\n",
        "        self.scaler = MinMaxScaler()\n",
        "        self.kmeans = None\n",
        "        self.X_scaled = None\n",
        "        self.cluster_labels = None\n",
        "        self.df_clustered = None\n",
        "        self.X_pca = None\n",
        "\n",
        "\n",
        "    def limpiar_X(self, X):\n",
        "        X = X.select_dtypes(include=[np.number])\n",
        "        for col in X.columns:\n",
        "            is_pos_inf = X[col] == np.inf\n",
        "            is_neg_inf = X[col] == -np.inf\n",
        "            is_nan = X[col].isna()\n",
        "            valid_values = X[col][~(is_pos_inf | is_neg_inf | is_nan)]\n",
        "            max_val = valid_values.max()\n",
        "            min_val = valid_values[valid_values >= 0].min()\n",
        "            X.loc[is_pos_inf, col] = max_val\n",
        "            X.loc[is_neg_inf | is_nan, col] = min_val\n",
        "        return X\n",
        "\n",
        "    def preprocess(self):\n",
        "        X = self.df.iloc[:, 10:]\n",
        "        columnas_validas = [col for col in X.columns if self.year_column_filter in col]\n",
        "        X = X[columnas_validas]\n",
        "        X = X.select_dtypes(include=[np.number])\n",
        "        X = self.limpiar_X(X)\n",
        "        self.X_scaled = self.scaler.fit_transform(X)\n",
        "        return self.X_scaled\n",
        "\n",
        "    def aplicar_pca(self, n_componentes=2):\n",
        "        \"\"\"\n",
        "        Aplica PCA para reducir la dimensionalidad de los datos escalados.\n",
        "\n",
        "        Parámetros\n",
        "        ----------\n",
        "        n_componentes : int\n",
        "            Número de componentes principales a calcular (por defecto 2).\n",
        "\n",
        "        Retorna\n",
        "        -------\n",
        "        np.ndarray\n",
        "            Datos proyectados en el nuevo espacio reducido.\n",
        "        \"\"\"\n",
        "        pca = PCA(n_components=n_componentes)\n",
        "        self.X_pca = pca.fit_transform(self.X_scaled)\n",
        "        return self.X_pca\n",
        "\n",
        "\n",
        "    def run_kmeans(self, usar_pca=False):\n",
        "        \"\"\"\n",
        "        Aplica KMeans a los datos escalados o reducidos con PCA.\n",
        "\n",
        "        Parámetros\n",
        "        ----------\n",
        "        usar_pca : bool\n",
        "            Si es True, se utiliza la proyección PCA en lugar de los datos escalados.\n",
        "\n",
        "        Retorna\n",
        "        -------\n",
        "        np.ndarray\n",
        "            Etiquetas de clúster asignadas por KMeans.\n",
        "        \"\"\"\n",
        "        if usar_pca and self.X_pca is not None:\n",
        "            datos_para_clustering = self.X_pca\n",
        "        else:\n",
        "            datos_para_clustering = self.X_scaled\n",
        "\n",
        "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=54163312)\n",
        "        self.cluster_labels = self.kmeans.fit_predict(datos_para_clustering)\n",
        "        self.df_clustered = self.df.copy()\n",
        "        self.df_clustered[\"Cluster\"] = self.cluster_labels\n",
        "        return self.cluster_labels\n",
        "\n",
        "\n",
        "    def mostrar_resultados_clustering(self):\n",
        "        \"\"\"\n",
        "        Muestra un resumen de los clústeres obtenidos con KMeans.\n",
        "\n",
        "        Incluye el número de observaciones por clúster y ejemplos\n",
        "        representativos de cada uno.\n",
        "        \"\"\"\n",
        "        if self.cluster_labels is None:\n",
        "            print(\"Asegúrate de haber ejecutado primero el método de clustering.\")\n",
        "            return\n",
        "\n",
        "        df_resultado = self.df.copy()\n",
        "        df_resultado['Cluster'] = self.cluster_labels\n",
        "        conteo = df_resultado['Cluster'].value_counts().sort_index()\n",
        "        print(\"Número de observaciones por clúster:\")\n",
        "        for i, count in conteo.items():\n",
        "            print(f\"  - Clúster {i}: {count} observaciones\")\n",
        "\n",
        "        for i in sorted(df_resultado['Cluster'].unique()):\n",
        "            print(f\"\\nMuestra de observaciones del clúster {i}:\")\n",
        "            display(df_resultado[df_resultado['Cluster'] == i].head())\n",
        "\n",
        "        self.df_clasificado = df_resultado\n",
        "\n",
        "    def comparar_con_target(self, target_col='Target'):\n",
        "        \"\"\"\n",
        "        Compara la asignación de clústeres con una columna objetivo (por ejemplo, quiebra/saludable).\n",
        "\n",
        "        Parámetros\n",
        "        ----------\n",
        "        target_col : str\n",
        "            Nombre de la columna del DataFrame original con las clases reales.\n",
        "        \"\"\"\n",
        "        if self.kmeans is None or self.df is None:\n",
        "            print(\"Debes haber ejecutado `run_kmeans()` primero.\")\n",
        "            return\n",
        "\n",
        "        if target_col not in self.df.columns:\n",
        "            print(f\"No se encontró la columna '{target_col}' en los datos originales.\")\n",
        "            return\n",
        "\n",
        "        df_resultado = self.df.copy()\n",
        "        df_resultado['Cluster'] = self.kmeans.labels_\n",
        "\n",
        "        comparacion = pd.crosstab(df_resultado['Cluster'], df_resultado[target_col])\n",
        "        print(\"Comparativa entre clústeres y clases reales:\")\n",
        "        display(comparacion)\n",
        "\n",
        "        print(\"\\nProporción por clúster:\")\n",
        "        display(comparacion.div(comparacion.sum(axis=1), axis=0).round(2))\n",
        "\n",
        "        self.df_clasificado = df_resultado\n",
        "\n",
        "    def plot_clusters(self, nombres_cluster=None):\n",
        "        \"\"\"\n",
        "        Visualiza los clústeres en 2D usando los datos reducidos por PCA y segmentados por Kmeans\n",
        "\n",
        "        Parámetros\n",
        "        ----------\n",
        "        nombres_cluster : dict, opcional\n",
        "            Diccionario que mapea etiquetas numéricas de clúster a nombres personalizados.\n",
        "        \"\"\"\n",
        "        if self.X_pca is None:\n",
        "            print(\"Primero ejecuta `aplicar_pca()` para visualizar en 2D.\")\n",
        "            return\n",
        "\n",
        "        # Crear etiquetas descriptivas si se proporciona el mapeo\n",
        "        if nombres_cluster:\n",
        "            etiquetas = pd.Series(self.cluster_labels).map(nombres_cluster)\n",
        "        else:\n",
        "            etiquetas = pd.Series(self.cluster_labels)\n",
        "\n",
        "        etiquetas = pd.Categorical(etiquetas)\n",
        "\n",
        "        plt.figure(figsize=(8, 6))\n",
        "        scatter = sns.scatterplot(x=self.X_pca[:, 0], y=self.X_pca[:, 1], hue=etiquetas, palette=\"Set2\", s=60)\n",
        "\n",
        "        plt.title(\"Visualización de Clusters en 2D\")\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "\n",
        "        plt.grid(True)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "\n",
        "    def plot_elbow_method(self, max_k=10):\n",
        "        \"\"\"\n",
        "        Aplica el método del codo para determinar el número óptimo de clusters para KMeans.\n",
        "\n",
        "        Args:\n",
        "            max_k (int): Número máximo de clusters a probar (por defecto 10).\n",
        "        \"\"\"\n",
        "        if self.X_scaled is None:\n",
        "            print(\"Primero ejecuta `preprocess()` para escalar los datos.\")\n",
        "            return\n",
        "\n",
        "        sse = []\n",
        "        ks = range(1, max_k + 1)\n",
        "\n",
        "        for k in ks:\n",
        "            kmeans = KMeans(n_clusters=k, random_state=54163312)\n",
        "            kmeans.fit(self.X_scaled)\n",
        "            sse.append(kmeans.inertia_)\n",
        "\n",
        "        plt.figure(figsize=(8, 5))\n",
        "        plt.plot(ks, sse, marker='o')\n",
        "        plt.xticks(ks)\n",
        "        plt.xlabel(\"Número de clusters (k)\")\n",
        "        plt.ylabel(\"Inercia\")\n",
        "        plt.title(\"Método del Codo para determinar k óptimo\")\n",
        "        plt.grid(True)\n",
        "        plt.show()\n",
        "\n",
        "    def variables_mas_representativas(self, top_n=5):\n",
        "        \"\"\"\n",
        "        Identifica las variables más representativas por clúster según la desviación respecto a la media global.\n",
        "\n",
        "        Args:\n",
        "            top_n (int): Número de variables principales por clúster a mostrar.\n",
        "\n",
        "        Returns:\n",
        "            dict: Diccionario con clústeres como claves y listas de variables destacadas como valores.\n",
        "        \"\"\"\n",
        "        if self.df_clustered is None:\n",
        "            print(\"Primero ejecuta `run_kmeans()`.\")\n",
        "            return\n",
        "\n",
        "        # Filtrar columnas numéricas relevantes\n",
        "        columnas = [col for col in self.df_clustered.columns[10:] if self.year_column_filter in col]\n",
        "        df_vars = self.df_clustered[columnas].select_dtypes(include=[np.number])\n",
        "        df_vars[\"Cluster\"] = self.df_clustered[\"Cluster\"]\n",
        "\n",
        "        # Calcular media global y por clúster\n",
        "        medias_globales = df_vars.drop(columns=\"Cluster\").mean()\n",
        "        resultado = {}\n",
        "\n",
        "        for cl in sorted(df_vars[\"Cluster\"].unique()):\n",
        "            df_cl = df_vars[df_vars[\"Cluster\"] == cl].drop(columns=\"Cluster\")\n",
        "            media_cl = df_cl.mean()\n",
        "            desviacion = ((media_cl - medias_globales).abs()).sort_values(ascending=False)\n",
        "            resultado[cl] = list(desviacion.head(top_n).index)\n",
        "\n",
        "        return resultado\n",
        "\n",
        "    def exportar_resultado_a_excel(self, ruta_salida=\"empresas_clasificadas.xlsx\"):\n",
        "        \"\"\"\n",
        "        Exporta el DataFrame con la asignación de clústeres a un archivo Excel.\n",
        "\n",
        "        Args:\n",
        "            ruta_salida (str): Ruta donde se guardará el archivo Excel resultante.\n",
        "        \"\"\"\n",
        "        if self.df_clustered is None:\n",
        "            print(\"Debes ejecutar `run_kmeans()` antes de exportar.\")\n",
        "            return\n",
        "\n",
        "        self.df_clustered.to_excel(ruta_salida, index=False)\n",
        "        print(f\"Archivo exportado correctamente a: {ruta_salida}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdUjCssvN_GL"
      },
      "outputs": [],
      "source": [
        "# Crear una instancia del analizador de clústeres con el Excel dado\n",
        "analyzer = ClusteringAnalyzer(ruta_excel='/content/cluster.xlsx', year_column_filter=\"2021\")\n",
        "\n",
        "# Preprocesar los datos: filtrar columnas del año, limpiar valores anómalos y escalar los datos\n",
        "analyzer.preprocess()\n",
        "\n",
        "# Aplicar PCA para reducir a 2 dimensiones y poder visualizar en un plano\n",
        "analyzer.aplicar_pca(n_componentes=2)\n",
        "\n",
        "# Usar el método del codo para analizar cuántos clústeres podrían ser óptimos\n",
        "analyzer.plot_elbow_method(max_k=10)\n",
        "\n",
        "# Elegir 4 clústeres manualmente (por ejemplo, tras ver el gráfico del codo)\n",
        "analyzer.n_clusters = 4\n",
        "\n",
        "# Ejecutar KMeans con los datos proyectados en PCA\n",
        "analyzer.run_kmeans(usar_pca=True)\n",
        "\n",
        "# Mostrar cuántas empresas hay en cada clúster y ejemplos representativos\n",
        "analyzer.mostrar_resultados_clustering()\n",
        "\n",
        "# Etiquetas descriptivas para entender mejor qué representa cada clúster después de haberlos estudiado previamente\n",
        "nombre_clusters = {\n",
        "    0: \"Fragilidad financiera\",\n",
        "    1: \"Baja eficiencia en activos\",\n",
        "    2: \"Elevada solvencia y liquidez\",\n",
        "    3: \"Fuerte liquidez y estructuras ligeras\"\n",
        "}\n",
        "\n",
        "# Dibujar los puntos (empresas) en el plano 2D con colores y etiquetas por clúster\n",
        "analyzer.plot_clusters(nombres_cluster=nombre_clusters)\n",
        "\n",
        "# Identificar las variables que mejor definen a cada clúster (top 5 por desviación respecto a la media global)\n",
        "variables_destacadas = analyzer.variables_mas_representativas(top_n=5)\n",
        "\n",
        "# Imprimir por pantalla las variables clave de cada clúster\n",
        "for cluster, variables in variables_destacadas.items():\n",
        "    print(f\"\\nClúster {cluster} – Variables más distintivas:\")\n",
        "    for var in variables:\n",
        "        print(f\"  - {var}\")\n",
        "\n",
        "# Exportar todo el DataFrame (original + columna Cluster) a un archivo Excel\n",
        "analyzer.exportar_resultado_a_excel(\"/content/empresas_con_cluster.xlsx\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "3Ubnei59PSUZ",
        "D3yKar4xY9q9",
        "avk05J_25OL8",
        "tlTsL7OF0EhS",
        "3C7fMZ9M5tF0",
        "837VSo6y5IG3",
        "ywGmvAxGB9Se"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}